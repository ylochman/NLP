{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transition-based arc-eager unlabeled dependency parser for Ukrainian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data\n",
    "\n",
    "Useful links:\n",
    "* [UD corpus for Ukrainian](https://github.com/UniversalDependencies/UD_Ukrainian-IU/)\n",
    "* [Easy-to-use library for parsing UD](https://github.com/EmilStenstrom/conllu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'UD_Ukrainian-IU/uk_iu-ud-train.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b7f58af58a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"UD_Ukrainian-IU\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/uk_iu-ud-train.conllu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'UD_Ukrainian-IU/uk_iu-ud-train.conllu'"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from conllu import parse\n",
    "from enum import Enum\n",
    "\n",
    "PATH = \"UD_Ukrainian-IU\"\n",
    "\n",
    "with open(PATH + \"/uk_iu-ud-train.conllu\", \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "trees = parse(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = trees[0]\n",
    "print(tree[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in tree:\n",
    "    head = node[\"head\"]\n",
    "    print(\"{} <-- {}\".format(node[\"form\"],\n",
    "                             tree[head - 1][\"form\"]\n",
    "                             if head > 0 else \"root\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design actions and the oracle\n",
    "\n",
    "We will be using a static oracle that reproduces a single valid order of actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(str, Enum):\n",
    "    SHIFT = \"shift\"\n",
    "    REDUCE = \"reduce\"\n",
    "    RIGHT = \"right\"\n",
    "    LEFT = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle(stack, top_queue, relations):\n",
    "    \"\"\"\n",
    "    Make a decision on the right action to do.\n",
    "    \"\"\"\n",
    "    top_stack = stack[-1]\n",
    "    # check if both stack and queue are non-empty\n",
    "    if top_stack and not top_queue:\n",
    "        return Actions.REDUCE\n",
    "    # check if there are any clear dependencies\n",
    "    elif top_queue[\"head\"] == top_stack[\"id\"]:\n",
    "        return Actions.RIGHT\n",
    "    elif top_stack[\"head\"] == top_queue[\"id\"]:\n",
    "        return Actions.LEFT\n",
    "    # check if we can reduce the top of the stack\n",
    "    elif top_stack[\"id\"] in [i[0] for i in relations] and \\\n",
    "         (top_queue[\"head\"] < top_stack[\"id\"] or \\\n",
    "          [s for s in stack if s[\"head\"] == top_queue[\"id\"]]):\n",
    "        return Actions.REDUCE\n",
    "    # default option\n",
    "    else:\n",
    "        return Actions.SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])\n",
    "\n",
    "def trace_actions(tree, log=True):\n",
    "    \"\"\"\n",
    "    Try out the oracle to verify it's returning the right actions.\n",
    "    \"\"\"\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue[0] if len(queue) > 0 else None,\n",
    "                        relations)\n",
    "        if log:\n",
    "            print(\"Stack:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in stack])\n",
    "            print(\"Queue:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in queue])\n",
    "            print(\"Relations:\", relations)\n",
    "            print(action)\n",
    "            print(\"========================\")\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    if log:\n",
    "        print(\"Gold relations:\")\n",
    "        print([(node[\"id\"], node[\"head\"]) for node in tree])\n",
    "        print(\"Retrieved relations:\")\n",
    "        print(sorted(relations))\n",
    "\n",
    "trace_actions(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "Reference: [Dependency Parsing by KÃ¼bler, McDonald, and Nivre](https://books.google.com.ua/books?id=k3iiup7HB9UC&pg=PA21&hl=uk&source=gbs_toc_r&cad=4#v=onepage&q&f=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(stack, queue):\n",
    "    features = dict()\n",
    "    if len(stack) > 0:\n",
    "        stack_top = stack[-1]\n",
    "        features[\"s0-word\"] = stack_top[\"form\"]\n",
    "        features[\"s0-lemma\"] = stack_top[\"lemma\"]\n",
    "        features[\"s0-tag\"] = stack_top[\"upostag\"]\n",
    "        if stack_top[\"feats\"]:\n",
    "            for k, v in stack_top[\"feats\"].items():\n",
    "                features[\"s0-\" + k] = v\n",
    "    if len(stack) > 1:\n",
    "        features[\"s1-tag\"] = stack_top[\"upostag\"]\n",
    "    if queue:\n",
    "        queue_top = queue[0]\n",
    "        features[\"q0-word\"] = queue_top[\"form\"]\n",
    "        features[\"q0-lemma\"] = queue_top[\"lemma\"]\n",
    "        features[\"q0-tag\"] = queue_top[\"upostag\"]\n",
    "        if queue_top[\"feats\"]:\n",
    "            for k, v in queue_top[\"feats\"].items():\n",
    "                features[\"q0-\" + k] = v\n",
    "    if len(queue) > 1:\n",
    "        queue_next = queue[1]\n",
    "        features[\"q1-word\"] = queue_next[\"form\"]\n",
    "        features[\"q1-tag\"] = queue_next[\"upostag\"]\n",
    "    if len(queue) > 2:\n",
    "        features[\"q2-tag\"] = queue[2][\"upostag\"]\n",
    "    if len(queue) > 3:\n",
    "        features[\"q3-tag\"] = queue[3][\"upostag\"]\n",
    "    if stack and queue:\n",
    "        features[\"distance\"] = queue[0][\"id\"] - stack[-1][\"id\"]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tree):\n",
    "    features, labels = [], []\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue[0] if len(queue) > 0 else None,\n",
    "                        relations)\n",
    "        features.append(extract_features(stack, queue))\n",
    "        labels.append(action.value)\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features, labels = get_data(tree)\n",
    "print(\"Number of words:\", len(tree))\n",
    "print(\"Number of actions:\", len(labels))\n",
    "print(\"List of actions taken:\", labels)\n",
    "print(\"Features:\")\n",
    "for word in features:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = [], []\n",
    "for tree in trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    train_features += tree_features\n",
    "    train_labels += tree_labels\n",
    "\n",
    "print(len(train_features), len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "\n",
    "with open(PATH + \"/uk_iu-ud-test.conllu\", \"r\") as f:\n",
    "    data = f.read()\n",
    "test_trees = parse(data)\n",
    "\n",
    "test_features, test_labels = [], []\n",
    "for tree in test_trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    test_features += tree_features\n",
    "    test_labels += tree_labels\n",
    "\n",
    "print(len(test_features), len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "vec = vectorizer.fit(train_features)\n",
    "\n",
    "print(\"\\nTotal number of features: \", len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_vectorized = vec.transform(train_features)\n",
    "test_features_vectorized = vec.transform(test_features)\n",
    "\n",
    "#print(len(train_features_vectorized.toarray()), len(test_features_vectorized.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc = LogisticRegression(random_state=42, solver=\"sag\", multi_class=\"multinomial\", max_iter=1000, verbose=1)\n",
    "lrc.fit(train_features_vectorized, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = lrc.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the unlabeled attachment score\n",
    "UAS - the percentage of words in an input that are assigned the correct head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_parse(sentence, oracle, vectorizer, log=True):\n",
    "    stack, queue, relations = [ROOT], sentence[:], []\n",
    "    while queue or stack:\n",
    "        if stack and not queue:\n",
    "            stack.pop()\n",
    "        else:\n",
    "            features = extract_features(stack, queue)\n",
    "            action = oracle.predict(vectorizer.transform([features]))[0]\n",
    "            if log:\n",
    "                print(\"Stack:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in stack])\n",
    "                print(\"Queue:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in queue])\n",
    "                print(\"Relations:\", relations)\n",
    "                print(action)\n",
    "                print(\"========================\")\n",
    "            # actual parsing\n",
    "            if action == Actions.SHIFT:\n",
    "                stack.append(queue.pop(0))\n",
    "            elif action == Actions.REDUCE:\n",
    "                stack.pop()\n",
    "            elif action == Actions.LEFT:\n",
    "                relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "                stack.pop()\n",
    "            elif action == Actions.RIGHT:\n",
    "                relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "                stack.append(queue.pop(0))\n",
    "            else:\n",
    "                print(\"Unknown action.\")\n",
    "    return sorted(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total, tp = 0, 0\n",
    "for tree in test_trees:\n",
    "    tree = [t for t in tree if type(t[\"id\"])==int]\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse(tree, lrc, vec)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
