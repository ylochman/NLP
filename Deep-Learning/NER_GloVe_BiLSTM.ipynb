{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition with GloVe-BiLSTM-Softmax model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as progress\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import rnn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Read and process NER 2003 English Shared Task data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(fpath):\n",
    "    \"\"\" Read NER 2003 English Shared Task data (CoNNL file format)\n",
    "    Data format:\n",
    "        All data files contain one word per line with empty lines\n",
    "        representing sentence boundaries. At the end of each line there is \n",
    "        tag which states whether the current word is inside a named entity or not.\n",
    "        The tag also encodes the type of named entity. Example\n",
    "        Example:\n",
    "            U.N. NNP I-NP I-ORG\n",
    "        Each line contains four fields:\n",
    "            [word] [POS tag] [chunk tag] [NE tag]\n",
    "            \n",
    "        Four different types of named entities: PERSON, LOCATION, ORGANIZATION, MISC.\n",
    "        \n",
    "    Args:\n",
    "        fpath: path to data file\n",
    "    Returns:\n",
    "        sentences_words: list of sentences' words (one sentence is a list of words)\n",
    "        sentences_tags: list of sentences' tags (one sentence is a list of tags corresponding to words)\n",
    "    \"\"\"\n",
    "    with open(fpath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    raw_sentences = []\n",
    "    i_prev, i_next = 0, 0\n",
    "    while i_next < len(lines):\n",
    "        if lines[i_next] == '\\n':\n",
    "            raw_sentences.append(lines[i_prev:i_next])\n",
    "            i_prev = i_next + 1\n",
    "        i_next += 1\n",
    "\n",
    "    sentences_words = []\n",
    "    sentences_tags = []\n",
    "    for sentence in raw_sentences:\n",
    "        words = [string.split()[0] for string in sentence]\n",
    "        tags = [string.split()[3] for string in sentence]\n",
    "        if words != ['-DOCSTART-']:\n",
    "            sentences_words.append(words)\n",
    "            sentences_tags.append(tags)\n",
    "    return list(zip(sentences_words, sentences_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train (14041), dev (3250), test (3453) data\n"
     ]
    }
   ],
   "source": [
    "root = './data'\n",
    "\n",
    "train_data = read_data('./data/train.txt')\n",
    "val_data = read_data('./data/dev.txt')\n",
    "test_data = read_data('./data/test.txt')\n",
    "\n",
    "print('Loaded train ({}), dev ({}), test ({}) data'.format(len(train_data),\n",
    "                                                          len(val_data),\n",
    "                                                          len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30289 words in vocabulary\n",
      "9 tags (IOB2 tagging scheme): dict_keys(['B-ORG', 'O', 'B-MISC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG', 'I-MISC', 'I-LOC'])\n"
     ]
    }
   ],
   "source": [
    "word_to_idx = {}  # vocabulary\n",
    "tag_to_idx = {}  # tagset\n",
    "\n",
    "for i, (sentence, tags) in enumerate(train_data + val_data + test_data):\n",
    "    for word in sentence:\n",
    "        if word not in word_to_idx:\n",
    "            word_to_idx[word] = len(word_to_idx)\n",
    "    for tag in tags:\n",
    "        if tag not in tag_to_idx:\n",
    "            tag_to_idx[tag] = len(tag_to_idx)\n",
    "\n",
    "vocab_size = len(word_to_idx)\n",
    "print(vocab_size, 'words in vocabulary')\n",
    "\n",
    "tagset_size = len(tag_to_idx)\n",
    "print(tagset_size, 'tags (IOB2 tagging scheme):', tag_to_idx.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f61c64afff4714b69ff6d6ab0f38e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GloVe for 400000 words loaded\n"
     ]
    }
   ],
   "source": [
    "with open('./glove/glove.6B.100d.txt', 'r') as f:\n",
    "    glove_raw = f.readlines()\n",
    "    \n",
    "glove = {line.split()[0]: torch.tensor([float(val) for val in line.split()[1:]])\n",
    "         for line in progress(glove_raw)}\n",
    "\n",
    "print('GloVe for {} words loaded'.format(len(glove)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe embeddings as dict vocabulary and embedding matrix of shape (30289, 100)\n",
      "Example embedding for `the`:\n",
      " tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
      "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
      "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
      "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
      "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
      "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
      "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
      "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
      "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
      "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
      "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
      "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
      "        -0.5203, -0.1459,  0.8278,  0.2706])\n"
     ]
    }
   ],
   "source": [
    "def get_gloves(seq, glove, strategy=3):\n",
    "    \"\"\"Get Global Vectors for Word Representation in a list of words\n",
    "    Args:\n",
    "        seq: list of words of size N\n",
    "        glove: GloVe dictionary of 400000 words, the format\n",
    "               {word: 100D vector representation}\n",
    "        strategy: 1, 2 or 3\n",
    "            1 -- load the embeddings for original capitalization of words.\n",
    "                 If embedding for this word doesn’t exists, associate\n",
    "                 it with <UNK> embedding.\n",
    "            2 -- load the embeddings for lowercased capitalization of words.\n",
    "                 If embedding for this lowercased word doesn’t exists,\n",
    "                 associate it with <UNK> embedding.\n",
    "            3 -- Для різної капіталізації слів завантажуємо одні і ті самі (lowercased)\n",
    "                 вектори ембедінгів, але в нашому словнику це різні слова.\n",
    "                 Тобто, “Hello” та “hello” відповідають фізично два вектори,\n",
    "                 які ідентичні за своїми значеннями перед тренуванням\n",
    "                 (якщо freeze_embeddings стоїть  False, то в процесі\n",
    "                 тренування вони будуть змінюватись).\n",
    "    Returns:\n",
    "        out_seq: a list of [100] tensors (GloVes) of size N\n",
    "    \"\"\"\n",
    "    assert strategy in [1,2,3]\n",
    "    \n",
    "    def associate_embedding(word):\n",
    "        if strategy == 1:\n",
    "            return glove['unk'] if word not in glove else glove[word]\n",
    "        if strategy == 2:\n",
    "            return glove['unk'] if word.lower() not in glove else glove[word.lower()]\n",
    "        return glove['unk'] if word.lower() not in glove else \\\n",
    "                glove[word.lower()] if word not in glove else glove[word]\n",
    "    \n",
    "    out_seq = [associate_embedding(w) for w in seq]\n",
    "    return out_seq, torch.stack(out_seq, 0)\n",
    "\n",
    "embedding_dim = 100\n",
    "strategy = 3\n",
    "\n",
    "gloves, gloves_matrix = get_gloves(word_to_idx.keys(), glove, strategy)\n",
    "word_to_glove = dict(zip(word_to_idx.keys(), gloves))\n",
    "print('Loaded GloVe embeddings as dict vocabulary and embedding matrix of shape',\n",
    "          tuple(gloves_matrix.shape))\n",
    "\n",
    "print('Example embedding for `the`:\\n', word_to_glove['the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-4. Train BiLSTM model on batches & test with micro-average Precision/Recall/F1/F0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        embedding_dim -- 100\n",
    "        hidden_dim -- hidden state dimensionality\n",
    "        vocab_size -- vocabulary size\n",
    "        tagset_size -- tag set size\n",
    "        pretrained_embeddings -- None or [vocab_size, embedding_dim] tensor\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size,\n",
    "                 pretrained_embeddings=None, strategy=2):\n",
    "\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.word_embeddings = nn.Embedding.from_pretrained(pretrained_embeddings,\n",
    "                                                                freeze=False)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim//2,\n",
    "                            bidirectional=True, batch_first=True)\n",
    "        self.tagger = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, inputs, packed_inputs=False):\n",
    "        if packed_inputs:\n",
    "            embeds = rnn.PackedSequence(self.word_embeddings(inputs.data), inputs.batch_sizes)\n",
    "        else:\n",
    "            embeds = self.word_embeddings(inputs).view(len(inputs), 1, -1)\n",
    "\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "\n",
    "        if packed_inputs:\n",
    "            tag_space = self.tagger(lstm_out.data)\n",
    "        else:\n",
    "            tag_space = self.tagger(lstm_out.view(len(inputs), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def seq_to_idxs(seq, mapping):\n",
    "    \"\"\"Converts a sequence of elements to sequence of indices\n",
    "       using given mapping\n",
    "\n",
    "    Args:\n",
    "        seq -- list of elements\n",
    "        mapping -- {element: idx} dict\n",
    "    \"\"\"\n",
    "    outs_seq = [torch.tensor(mapping[el], dtype=torch.long) for el in seq]\n",
    "    outs_seq = torch.stack(outs_seq, 0)\n",
    "    return outs_seq\n",
    "\n",
    "\n",
    "def calculate_scores(outputs, targets, log=False):\n",
    "    \"\"\"Calculate per-class and micro-average precision, recall, F-1 score and F-0.5 score\n",
    "    \n",
    "        Args:\n",
    "            outputs: tensor of log-softmax model outputs for the dataset\n",
    "            targets: tensor of true tag indices for the dataset\n",
    "            log: whether to print or not\n",
    "        Returns:\n",
    "            (micro-average) precision, recall, F-1 score, F-0.5 score\n",
    "    \"\"\"    \n",
    "    def F_score(precision, recall, beta=1):\n",
    "        return (1 + beta**2) * precision * recall / ((beta**2) * precision + recall + 1e-15)\n",
    "\n",
    "    pred = outputs.max(dim=1)[1]\n",
    "    TP, TN, FP, FN = torch.zeros(9), torch.zeros(9), torch.zeros(9), torch.zeros(9)\n",
    "    if log:\n",
    "        print('Tag\\tSize\\tPrecision\\tRecall\\t\\tF1\\tF0.5')\n",
    "    for tag in tag_to_idx.keys():\n",
    "        i = tag_to_idx[tag]\n",
    "        TP[i] = (pred[targets==i]==i).sum()\n",
    "        TN[i] = (pred[targets!=i]!=i).sum()\n",
    "        FP[i] = (pred[targets!=i]==i).sum()\n",
    "        FN[i] = (pred[targets==i]!=i).sum()\n",
    "\n",
    "        precision = float(TP[i] / (TP[i] + FP[i] + 1e-15))\n",
    "        recall = float(TP[i] / (TP[i] + FN[i] + 1e-15))\n",
    "        if log:\n",
    "            print('{}\\t{}\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\\t{:.4f}'.format(tag, len(targets[targets==i]),\n",
    "                                                                    precision, recall,\n",
    "                                                                    F_score(precision, recall, beta=1),\n",
    "                                                                    F_score(precision, recall, beta=0.5)))\n",
    "\n",
    "    MicroAvePrecision = float(TP.sum() / (TP.sum() + FP.sum()))\n",
    "    MicroAveRecall = float(TP.sum() / (TP.sum() + FN.sum()))\n",
    "    F1 = F_score(MicroAvePrecision, MicroAveRecall, beta=1)\n",
    "    F05 = F_score(MicroAvePrecision, MicroAveRecall, beta=0.5)\n",
    "    if log:\n",
    "        print('{}\\t{}\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\\t{:.4f}'.format('MICRO', len(targets),\n",
    "                                                                  MicroAvePrecision,\n",
    "                                                                  MicroAveRecall,\n",
    "                                                                  F1, F05))\n",
    "    return MicroAvePrecision, MicroAveRecall, F1, F05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model, loss_fn, optimizer, word_to_idx, tag_to_idx):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.tag_to_idx = tag_to_idx\n",
    "    \n",
    "    def run(self, num_epochs,\n",
    "            train_data, train_batch_size, val_data, val_batch_size,\n",
    "            log_interval=50):\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            self.__train(epoch, train_data, train_batch_size, log_interval)\n",
    "            self.__validate(epoch, val_data, val_batch_size)\n",
    "        \n",
    "    def __train(self, epoch, train_data, batch_size, log_interval=50):\n",
    "        losses = AverageMeter()\n",
    "        batch_time = AverageMeter()\n",
    "        batch_start = 0\n",
    "        batch_idx = 0\n",
    "        while batch_start < len(train_data):\n",
    "            end = time.time()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            batch = train_data[batch_start:batch_start + batch_size]\n",
    "            inputs_packed, targets_packed = self._prepare_batch(batch)\n",
    "            outputs = self.model(inputs_packed, True)\n",
    "\n",
    "            loss = self.loss_fn(outputs, targets_packed.data)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            losses.update(loss.item())\n",
    "            batch_time.update(time.time() - end)\n",
    "\n",
    "            batch_start += batch_size\n",
    "            batch_idx += 1\n",
    "            \n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {}\\t[{:>5}/{:<5}]\\tTime: {:.2f} ({:.2f})\\tLoss: {:.4f} ({:.4f})'.format(epoch,\n",
    "                    min(batch_start, len(train_data)), len(train_data),\n",
    "                    batch_time.val, batch_time.avg,\n",
    "                    losses.val, losses.avg))\n",
    "        print('====> Train. {}\\tTotal time: {:.2f}\\tAverage loss: {:.4f}'.format(\n",
    "              epoch, batch_time.sum, losses.avg))\n",
    "            \n",
    "            \n",
    "    def __validate(self, epoch, val_data, batch_size):\n",
    "        losses = AverageMeter()\n",
    "        batch_time = AverageMeter()\n",
    "        F1scores = AverageMeter()\n",
    "        F05scores = AverageMeter()\n",
    "        with torch.no_grad():\n",
    "            batch_start = 0\n",
    "            batch_idx = 0\n",
    "            while batch_start < len(val_data):\n",
    "                end = time.time()\n",
    "\n",
    "                batch = val_data[batch_start:batch_start + batch_size]\n",
    "                inputs_packed, targets_packed = self._prepare_batch(batch)\n",
    "                outputs = self.model(inputs_packed, True)\n",
    "\n",
    "                loss = self.loss_fn(outputs, targets_packed.data)\n",
    "                _, _, F1, F05 = calculate_scores(outputs, targets_packed.data, log=False)\n",
    "                F1scores.update(F1)\n",
    "                F05scores.update(F05)\n",
    "\n",
    "                losses.update(loss.item())\n",
    "                batch_time.update(time.time() - end)\n",
    "\n",
    "                batch_start += batch_size\n",
    "                batch_idx += 1\n",
    "        print('====> Valid. {}\\tTotal time: {:.2f}\\tAverage loss: {:.4f}\\tF-1: {:.4f}\\tF-0.5: {:.4f}\\t'.format(\n",
    "              epoch, batch_time.sum, losses.avg, F1scores.avg, F05scores.avg))\n",
    "            \n",
    "    def _prepare_batch(self, batch):\n",
    "        inputs_batch = [seq_to_idxs(seq[0], self.word_to_idx) for seq in batch]\n",
    "        targets_batch = [seq_to_idxs(seq[1], self.tag_to_idx) for seq in batch]\n",
    "\n",
    "        order = sorted(enumerate(inputs_batch), key=lambda x: len(x[1]), reverse=True)\n",
    "        inputs_batch = [inputs_batch[order_[0]] for order_ in order]\n",
    "        targets_batch = [targets_batch[order_[0]] for order_ in order]\n",
    "\n",
    "        inputs_packed = rnn.pack_sequence(inputs_batch)\n",
    "        targets_packed = rnn.pack_sequence(targets_batch)\n",
    "        return inputs_packed, targets_packed\n",
    "    \n",
    "    def test(self, test_data):\n",
    "        with torch.no_grad():\n",
    "            inputs_packed, targets_packed = self._prepare_batch(test_data)\n",
    "            outputs = self.model(inputs_packed, True)\n",
    "        calculate_scores(outputs, targets_packed.data, log=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\t[ 6400/14041]\tTime: 0.05 (0.05)\tLoss: 0.3927 (0.6942)\n",
      "Train Epoch: 1\t[12800/14041]\tTime: 0.07 (0.06)\tLoss: 0.3248 (0.5322)\n",
      "====> Train. 1\tTotal time: 6.31\tAverage loss: 0.5084\n",
      "====> Valid. 1\tTotal time: 0.58\tAverage loss: 0.3181\tF-1: 0.9102\tF-0.5: 0.9102\t\n",
      "Train Epoch: 2\t[ 6400/14041]\tTime: 0.06 (0.06)\tLoss: 0.2214 (0.2329)\n",
      "Train Epoch: 2\t[12800/14041]\tTime: 0.08 (0.06)\tLoss: 0.2100 (0.2248)\n",
      "====> Train. 2\tTotal time: 7.20\tAverage loss: 0.2191\n",
      "====> Valid. 2\tTotal time: 0.60\tAverage loss: 0.3038\tF-1: 0.9153\tF-0.5: 0.9153\t\n",
      "Train Epoch: 3\t[ 6400/14041]\tTime: 0.07 (0.07)\tLoss: 0.1591 (0.1636)\n",
      "Train Epoch: 3\t[12800/14041]\tTime: 0.08 (0.07)\tLoss: 0.1631 (0.1646)\n",
      "====> Train. 3\tTotal time: 7.77\tAverage loss: 0.1614\n",
      "====> Valid. 3\tTotal time: 0.62\tAverage loss: 0.2949\tF-1: 0.9180\tF-0.5: 0.9180\t\n",
      "Train Epoch: 4\t[ 6400/14041]\tTime: 0.07 (0.07)\tLoss: 0.1470 (0.1374)\n",
      "Train Epoch: 4\t[12800/14041]\tTime: 0.09 (0.07)\tLoss: 0.1527 (0.1403)\n",
      "====> Train. 4\tTotal time: 7.98\tAverage loss: 0.1387\n",
      "====> Valid. 4\tTotal time: 0.63\tAverage loss: 0.3030\tF-1: 0.9179\tF-0.5: 0.9179\t\n",
      "Train Epoch: 5\t[ 6400/14041]\tTime: 0.07 (0.07)\tLoss: 0.1373 (0.1257)\n",
      "Train Epoch: 5\t[12800/14041]\tTime: 0.09 (0.07)\tLoss: 0.1529 (0.1282)\n",
      "====> Train. 5\tTotal time: 8.08\tAverage loss: 0.1265\n",
      "====> Valid. 5\tTotal time: 0.64\tAverage loss: 0.3012\tF-1: 0.9193\tF-0.5: 0.9193\t\n",
      "Train Epoch: 6\t[ 6400/14041]\tTime: 0.07 (0.07)\tLoss: 0.1280 (0.1154)\n",
      "Train Epoch: 6\t[12800/14041]\tTime: 0.08 (0.07)\tLoss: 0.1531 (0.1199)\n",
      "====> Train. 6\tTotal time: 7.93\tAverage loss: 0.1192\n",
      "====> Valid. 6\tTotal time: 0.63\tAverage loss: 0.3188\tF-1: 0.9157\tF-0.5: 0.9157\t\n",
      "Train Epoch: 7\t[ 6400/14041]\tTime: 0.07 (0.07)\tLoss: 0.1228 (0.1141)\n",
      "Train Epoch: 7\t[12800/14041]\tTime: 0.08 (0.07)\tLoss: 0.1309 (0.1143)\n",
      "====> Train. 7\tTotal time: 7.85\tAverage loss: 0.1137\n",
      "====> Valid. 7\tTotal time: 0.63\tAverage loss: 0.3374\tF-1: 0.9148\tF-0.5: 0.9148\t\n",
      "Train Epoch: 8\t[ 6400/14041]\tTime: 0.07 (0.07)\tLoss: 0.1377 (0.1149)\n",
      "Train Epoch: 8\t[12800/14041]\tTime: 0.09 (0.07)\tLoss: 0.1254 (0.1180)\n",
      "====> Train. 8\tTotal time: 7.81\tAverage loss: 0.1162\n",
      "====> Valid. 8\tTotal time: 0.63\tAverage loss: 0.3221\tF-1: 0.9182\tF-0.5: 0.9182\t\n",
      "Tag\tSize\tPrecision\tRecall\t\tF1\tF0.5\n",
      "B-ORG\t1661\t0.5008\t\t0.5376\t\t0.5186\t0.5078\n",
      "O\t38323\t0.9600\t\t0.9545\t\t0.9573\t0.9589\n",
      "B-MISC\t702\t0.5771\t\t0.6182\t\t0.5970\t0.5849\n",
      "B-PER\t1617\t0.6232\t\t0.4960\t\t0.5523\t0.5928\n",
      "I-PER\t1156\t0.6522\t\t0.4801\t\t0.5531\t0.6086\n",
      "B-LOC\t1668\t0.5991\t\t0.7812\t\t0.6781\t0.6284\n",
      "I-ORG\t835\t0.5135\t\t0.5485\t\t0.5304\t0.5201\n",
      "I-MISC\t216\t0.4803\t\t0.5648\t\t0.5191\t0.4951\n",
      "I-LOC\t257\t0.3947\t\t0.5175\t\t0.4478\t0.4143\n",
      "MICRO\t46435\t0.8890\t\t0.8890\t\t0.8890\t0.8890\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 64\n",
    "learning_rate = 0.1\n",
    "\n",
    "model = LSTMTagger(embedding_dim=embedding_dim,\n",
    "                   hidden_dim=hidden_dim,\n",
    "                   vocab_size=vocab_size,\n",
    "                   tagset_size=tagset_size)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_batch_size = 128\n",
    "val_batch_size = 128\n",
    "\n",
    "trainer = Trainer(model, loss_function, optimizer, word_to_idx, tag_to_idx)\n",
    "trainer.run(8, train_data, train_batch_size, val_data, val_batch_size)\n",
    "trainer.test(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Compare the performances (F1 and F0.5 scores) for each strategy of loading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy 1\n",
      "Loaded GloVe embeddings as dict vocabulary and embedding matrix of shape (30289, 100)\n",
      "====> Train. 1\tTotal time: 6.32\tAverage loss: 0.5199\n",
      "====> Valid. 1\tTotal time: 0.57\tAverage loss: 0.3258\tF-1: 0.9071\tF-0.5: 0.9071\t\n",
      "====> Train. 2\tTotal time: 7.09\tAverage loss: 0.2244\n",
      "====> Valid. 2\tTotal time: 0.59\tAverage loss: 0.2948\tF-1: 0.9166\tF-0.5: 0.9166\t\n",
      "====> Train. 3\tTotal time: 7.78\tAverage loss: 0.1641\n",
      "====> Valid. 3\tTotal time: 0.60\tAverage loss: 0.3123\tF-1: 0.9154\tF-0.5: 0.9154\t\n",
      "====> Train. 4\tTotal time: 8.01\tAverage loss: 0.1399\n",
      "====> Valid. 4\tTotal time: 0.64\tAverage loss: 0.3198\tF-1: 0.9158\tF-0.5: 0.9158\t\n",
      "====> Train. 5\tTotal time: 8.06\tAverage loss: 0.1311\n",
      "====> Valid. 5\tTotal time: 0.62\tAverage loss: 0.3137\tF-1: 0.9169\tF-0.5: 0.9169\t\n",
      "Tag\tSize\tPrecision\tRecall\t\tF1\tF0.5\n",
      "B-ORG\t1661\t0.4756\t\t0.5575\t\t0.5133\t0.4900\n",
      "O\t38323\t0.9599\t\t0.9536\t\t0.9568\t0.9587\n",
      "B-MISC\t702\t0.5253\t\t0.5627\t\t0.5433\t0.5323\n",
      "B-PER\t1617\t0.5961\t\t0.5065\t\t0.5476\t0.5757\n",
      "I-PER\t1156\t0.6593\t\t0.4888\t\t0.5614\t0.6163\n",
      "B-LOC\t1668\t0.6405\t\t0.7764\t\t0.7019\t0.6637\n",
      "I-ORG\t835\t0.4415\t\t0.5150\t\t0.4754\t0.4544\n",
      "I-MISC\t216\t0.5023\t\t0.4954\t\t0.4988\t0.5009\n",
      "I-LOC\t257\t0.4292\t\t0.3774\t\t0.4017\t0.4177\n",
      "MICRO\t46435\t0.8868\t\t0.8868\t\t0.8868\t0.8868\n",
      "\n",
      "Strategy 2\n",
      "Loaded GloVe embeddings as dict vocabulary and embedding matrix of shape (30289, 100)\n",
      "====> Train. 1\tTotal time: 6.58\tAverage loss: 0.5185\n",
      "====> Valid. 1\tTotal time: 0.59\tAverage loss: 0.3242\tF-1: 0.9069\tF-0.5: 0.9069\t\n",
      "====> Train. 2\tTotal time: 7.32\tAverage loss: 0.2146\n",
      "====> Valid. 2\tTotal time: 0.61\tAverage loss: 0.2982\tF-1: 0.9174\tF-0.5: 0.9174\t\n",
      "====> Train. 3\tTotal time: 7.93\tAverage loss: 0.1602\n",
      "====> Valid. 3\tTotal time: 0.62\tAverage loss: 0.3097\tF-1: 0.9138\tF-0.5: 0.9138\t\n",
      "====> Train. 4\tTotal time: 8.09\tAverage loss: 0.1382\n",
      "====> Valid. 4\tTotal time: 0.63\tAverage loss: 0.3127\tF-1: 0.9174\tF-0.5: 0.9174\t\n",
      "====> Train. 5\tTotal time: 7.96\tAverage loss: 0.1254\n",
      "====> Valid. 5\tTotal time: 0.65\tAverage loss: 0.3236\tF-1: 0.9170\tF-0.5: 0.9170\t\n",
      "Tag\tSize\tPrecision\tRecall\t\tF1\tF0.5\n",
      "B-ORG\t1661\t0.5253\t\t0.5250\t\t0.5251\t0.5252\n",
      "O\t38323\t0.9618\t\t0.9551\t\t0.9584\t0.9604\n",
      "B-MISC\t702\t0.4839\t\t0.5997\t\t0.5356\t0.5033\n",
      "B-PER\t1617\t0.5696\t\t0.5263\t\t0.5471\t0.5604\n",
      "I-PER\t1156\t0.6852\t\t0.4593\t\t0.5500\t0.6238\n",
      "B-LOC\t1668\t0.6248\t\t0.7668\t\t0.6886\t0.6488\n",
      "I-ORG\t835\t0.4635\t\t0.5772\t\t0.5141\t0.4825\n",
      "I-MISC\t216\t0.5000\t\t0.4815\t\t0.4906\t0.4962\n",
      "I-LOC\t257\t0.4504\t\t0.4942\t\t0.4712\t0.4585\n",
      "MICRO\t46435\t0.8888\t\t0.8888\t\t0.8888\t0.8888\n",
      "\n",
      "Strategy 3\n",
      "Loaded GloVe embeddings as dict vocabulary and embedding matrix of shape (30289, 100)\n",
      "====> Train. 1\tTotal time: 6.61\tAverage loss: 0.4984\n",
      "====> Valid. 1\tTotal time: 0.58\tAverage loss: 0.3129\tF-1: 0.9104\tF-0.5: 0.9104\t\n",
      "====> Train. 2\tTotal time: 7.49\tAverage loss: 0.2144\n",
      "====> Valid. 2\tTotal time: 0.63\tAverage loss: 0.2936\tF-1: 0.9169\tF-0.5: 0.9169\t\n",
      "====> Train. 3\tTotal time: 7.99\tAverage loss: 0.1653\n",
      "====> Valid. 3\tTotal time: 0.62\tAverage loss: 0.3028\tF-1: 0.9172\tF-0.5: 0.9172\t\n",
      "====> Train. 4\tTotal time: 8.38\tAverage loss: 0.1420\n",
      "====> Valid. 4\tTotal time: 0.63\tAverage loss: 0.2996\tF-1: 0.9184\tF-0.5: 0.9184\t\n",
      "====> Train. 5\tTotal time: 8.22\tAverage loss: 0.1267\n",
      "====> Valid. 5\tTotal time: 0.63\tAverage loss: 0.3113\tF-1: 0.9171\tF-0.5: 0.9171\t\n",
      "Tag\tSize\tPrecision\tRecall\t\tF1\tF0.5\n",
      "B-ORG\t1661\t0.4410\t\t0.5467\t\t0.4882\t0.4587\n",
      "O\t38323\t0.9631\t\t0.9500\t\t0.9565\t0.9604\n",
      "B-MISC\t702\t0.5259\t\t0.5641\t\t0.5443\t0.5331\n",
      "B-PER\t1617\t0.6092\t\t0.5090\t\t0.5546\t0.5861\n",
      "I-PER\t1156\t0.7537\t\t0.5718\t\t0.6503\t0.7086\n",
      "B-LOC\t1668\t0.6002\t\t0.7344\t\t0.6606\t0.6230\n",
      "I-ORG\t835\t0.4235\t\t0.5401\t\t0.4747\t0.4426\n",
      "I-MISC\t216\t0.6294\t\t0.5741\t\t0.6005\t0.6175\n",
      "I-LOC\t257\t0.3931\t\t0.4436\t\t0.4168\t0.4023\n",
      "MICRO\t46435\t0.8853\t\t0.8853\t\t0.8853\t0.8853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for strategy in [1, 2, 3]:\n",
    "    print('Strategy', strategy)\n",
    "    \n",
    "    embedding_dim = 100\n",
    "\n",
    "    gloves, gloves_matrix = get_gloves(word_to_idx.keys(), glove, strategy)\n",
    "    word_to_glove = dict(zip(word_to_idx.keys(), gloves))\n",
    "    print('Loaded GloVe embeddings as dict vocabulary and embedding matrix of shape',\n",
    "              tuple(gloves_matrix.shape))\n",
    "    \n",
    "    hidden_dim = 64\n",
    "    learning_rate = 0.1\n",
    "\n",
    "    model = LSTMTagger(embedding_dim=embedding_dim,\n",
    "                       hidden_dim=hidden_dim,\n",
    "                       vocab_size=vocab_size,\n",
    "                       tagset_size=tagset_size)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_batch_size = 128\n",
    "    val_batch_size = 128\n",
    "\n",
    "    trainer = Trainer(model, loss_function, optimizer, word_to_idx, tag_to_idx)\n",
    "    trainer.run(5, train_data, train_batch_size, val_data, val_batch_size, log_interval=200)\n",
    "    trainer.test(test_data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The performance is comparable and quite good for all strategies :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
